{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLWCguDNpagL"
   },
   "source": [
    "# KDDCup99 Preprocessing\n",
    "#### This notebook implements data preprocessing on KDDCup datasets. The final outputs of this notebook are `2 different preprocessed datasets.`\n",
    "#### They are:\n",
    "* `KDDCup99-preprocessed-sub-features` data, which is a preprocessed dataset from main KDDCup99 dataset that contains all selected features for binary classification.\n",
    "* `KDDCup99-preprocessed-full-features` data, which is a preprocessed dataset from main KDDCup99 dataset that contains all the selected features for binary classification. The selected features are chosen based on Recursive Feature Elimination (RFE) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-cVunZgpgxZ"
   },
   "source": [
    "#### Recursive Feature Elimination (RFE) on KDDCup99. n is 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TazCkaFo6CxK",
    "outputId": "11f5b644-82b9-43e4-a36e-3ed980b45aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'hot',\n",
      "       'num_compromised', 'count', 'srv_count', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Step 1: Download the KDDCUP99 Dataset\n",
    "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "dataset_path = \"kddcup99_dataset.gz\"\n",
    "\n",
    "# Download the dataset\n",
    "try:\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "except ImportError:\n",
    "    import urllib\n",
    "    urllib.urlretrieve(url, dataset_path)\n",
    "\n",
    "# Step 2: Load the dataset into a Pandas DataFrame\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"target\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(dataset_path, names=column_names)\n",
    "\n",
    "# Step 3: Data preprocessing (convert non-numeric features to numeric)\n",
    "df['protocol_type'] = pd.Categorical(df['protocol_type']).codes\n",
    "df['service'] = pd.Categorical(df['service']).codes\n",
    "df['flag'] = pd.Categorical(df['flag']).codes\n",
    "df['target'] = pd.Categorical(df['target']).codes\n",
    "\n",
    "# Step 4: Perform Recursive Feature Elimination (RFE) with Random Forest\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create the RFE object and specify the number of features to select\n",
    "rfe = RFE(estimator=rf, n_features_to_select=16, step=1)\n",
    "\n",
    "# Fit the RFE model to the data\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZG1n6SMpQS1"
   },
   "source": [
    "#### Preprocessing for all features of KDDCup99 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8SnfjcqjcB5",
    "outputId": "e4e77761-7643-4050-a4fe-3d8059e1754a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Russell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "# Step 1.1: Load the dataset into a Pandas DataFrame\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"target\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"../../data/kddcup99_dataset.gz\", names=column_names)\n",
    "\n",
    "# Step 1.2: Separate categorical and numerical columns\n",
    "categorical_columns = ['protocol_type', 'service', 'flag']\n",
    "numerical_columns = [col for col in df.columns if col not in categorical_columns and col != 'target']\n",
    "\n",
    "# Step 1.3: Perform One-Hot Encoding for categorical columns\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_categorical = one_hot_encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Create a DataFrame for the encoded categorical columns\n",
    "df_encoded_categorical = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Step 1.4: Perform Min-Max Normalization for numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "normalized_numerical = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Create a DataFrame for the normalized numerical columns\n",
    "df_normalized_numerical = pd.DataFrame(normalized_numerical, columns=numerical_columns)\n",
    "\n",
    "# Combine the encoded categorical and normalized numerical DataFrames\n",
    "df_preprocessed = pd.concat([df_encoded_categorical, df_normalized_numerical], axis=1)\n",
    "df_preprocessed['target'] = df[\"target\"].map(lambda x: 0 if x == \"normal.\" else 1)\n",
    "\n",
    "\n",
    "df_preprocessed.to_csv(\"../../data/preprocessed/KDDCup99-preprocessed-full-features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpNMbh4ptJwX",
    "outputId": "85df0144-6675-41f7-ed90-82c2afd6be0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_preprocessed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBN_iscnqLp5"
   },
   "source": [
    "#### Preprocessing for selected features of KDDCup99 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NN5sTXdngIj",
    "outputId": "36a942d9-7f98-44f0-c5d5-576dc690f755"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "x = pd.DataFrame()\n",
    "\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"target\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"../../data/kddcup99_dataset.gz\", names=column_names)\n",
    "y = df[\"target\"]\n",
    "# Selected Features based on RFE on KDDCup99\n",
    "selected_features = ['protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'hot',\n",
    "                     'num_compromised', 'count', 'srv_count', 'same_srv_rate',\n",
    "                     'diff_srv_rate', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "                     'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "                     'dst_host_srv_diff_host_rate']\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "\n",
    "numerical_features = ['src_bytes', 'dst_bytes', 'hot', 'num_compromised', 'count', 'srv_count',\n",
    "                      'same_srv_rate', 'diff_srv_rate', 'dst_host_srv_count',\n",
    "                      'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "                      'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate']\n",
    "\n",
    "categorical_features = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "# Perform preprocessing on selected features\n",
    "scaler = MinMaxScaler()\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "x = pd.DataFrame() # a new empty dataframe. We will add preprocessed data into x dataframe. \n",
    "\n",
    "def min_max_normalize(column):\n",
    "    min_val = column.min()\n",
    "    max_val = column.max()\n",
    "    column_normalized = (column - min_val) / (max_val - min_val)\n",
    "    return column_normalized\n",
    "\n",
    "# We move forward Column by column to see which column is categorical or numerical.\n",
    "for i in range(len(selected_features)):\n",
    "    feature = selected_features[i]\n",
    "    if feature in categorical_features and feature in selected_features:\n",
    "        x = pd.concat([x, pd.get_dummies(df_selected[feature], prefix=feature, dtype='int8')],axis=1)\n",
    "    elif feature in numerical_features and feature in selected_features:\n",
    "        # Apply min-max normalization to the specified column\n",
    "        x = pd.concat([x, min_max_normalize(df_selected[feature])],axis=1)\n",
    "y = df[\"target\"].map(lambda x: 0 if x == \"normal.\" else 1)\n",
    "x = pd.concat([x, y],axis=1)\n",
    "# Step 4: Save the preprocessed selected features as a CSV file\n",
    "x.to_csv(\"../../data/preprocessed/KDDCup99-preprocessed-sub-features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gc5C0kDos08b",
    "outputId": "d69a3c93-0a6f-43fa-9e6a-222177f8bc4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
